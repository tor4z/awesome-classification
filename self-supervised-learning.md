# Awesome Self-Supervised Learning

* [arXiv 2020] Bootstrap Your Own Latent A New Approach to Self-Supervised Learning [paper](https://arxiv.org/pdf/2006.07733.pdf)

* [ICLR 2022] Understanding Dimensional Collapse in Contrastive Self-supervised Learning [paper](https://arxiv.org/pdf/2110.09348.pdf)

* [arXiv 2021] On Feature Decorrelation in Self-Supervised Learning [paper](https://arxiv.org/pdf/2105.00470.pdf)

* [ICCV 2021] Emerging Properties in Self-Supervised Vision Transformers [paper](https://arxiv.org/pdf/2104.14294.pdf) [code](https://github.com/facebookresearch/dino)

* [CVPR 2021] Exploring Simple Siamese Representation Learning [paper](https://arxiv.org/pdf/2011.10566.pdf) [code](https://github.com/facebookresearch/simsiam)

* [NPIS 2020] Representation Learning with Contrastive Predictive Coding [paper](https://proceedings.neurips.cc//paper/2020/file/5cd5058bca53951ffa7801bcdf421651-Paper.pdf) [code](https://github.com/jiamings/ml-cpc)

* [CVPR 2020] Momentum Contrast for Unsupervised Visual Representation Learning [paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/He_Momentum_Contrast_for_Unsupervised_Visual_Representation_Learning_CVPR_2020_paper.pdf) [code](https://github.com/facebookresearch/moco)

* [arXiv 2020] Improved Baselines with Momentum Contrastive Learning [paper](https://arxiv.org/pdf/2003.04297v1.pdf) [code](https://github.com/facebookresearch/moco/tree/main/moco)

* [arXiv 2021] An Empirical Study of Training Self-Supervised Vision Transformers [paper](https://arxiv.org/pdf/2104.02057.pdf) [code](https://github.com/facebookresearch/moco-v3)

* [arXiv 2021] Self-Supervised Learning with Swin Transformers [paper](https://arxiv.org/pdf/2105.04553v2.pdf) [code](https://github.com/SwinTransformer/Transformer-SSL)
