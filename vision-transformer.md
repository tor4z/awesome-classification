# Awesome vision transformer

* [NIPS 2021] Revitalizing CNN Attentions via Transformers in Self-Supervised Visual Representation Learning [paper](https://arxiv.org/pdf/2110.05340v1.pdf) [code](https://github.com/ChongjianGE/CARE)

* [ICLR 2020] BEIT: BERT Pre-Training of Image Transformers [paper](https://arxiv.org/pdf/2106.08254v1.pdf) [code](https://github.com/microsoft/unilm/tree/master/beit)

* [PAMI 2021] P2T: Pyramid Pooling Transformer for Scene Understanding [paper](https://arxiv.org/pdf/2106.12011v3.pdf) [code](https://github.com/yuhuan-wu/P2T)

* [arXiv 2021] VOLO: Vision Outlooker for Visual Recognition [paper](https://arxiv.org/pdf/2106.13112v2.pdf) [code](https://github.com/sail-sg/volo)

* [ICCV 2021] Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction without Convolutions [paper](https://arxiv.org/pdf/2102.12122.pdf) [code](https://github.com/whai362/PVT)

* [arXiv 2021] PVTv2: Improved Baselines with Pyramid Vision Transformer [paper](https://arxiv.org/pdf/2106.13797v4.pdf) [code](https://github.com/whai362/PVT)

* [NIPS 2021] Global Filter Networks for Image Classification [paper](https://arxiv.org/pdf/2107.00645v1.pdf) [code](https://github.com/raoyongming/GFNet)

* [NIPS 2021] Focal Self-attention for Local-Global Interactions in Vision Transformers [paper](https://arxiv.org/pdf/2107.00641v1.pdf) [code](https://github.com/microsoft/Focal-Transformer)

* [ICCV 2021] AutoFormer: Searching Transformers for Visual Recognition [paper](https://arxiv.org/pdf/2107.00651v1.pdf) [code](https://github.com/microsoft/Cream)

* [ICCV 2021] GLiT: Neural Architecture Search for Global and Local Image Transformer [paper](https://arxiv.org/pdf/2107.02960v3.pdf) [code](https://github.com/bychen515/GLiT)

* [arXiv 2021] Visual Parser: Representing Part-whole Hierarchies with Transformers [paper](https://arxiv.org/pdf/2107.05790v1.pdf) [code](https://github.com/kevin-ssy/ViP)

* [ICCV 2021] Rethinking and Improving Relative Position Encoding for Vision Transformer [paper](https://arxiv.org/pdf/2107.14222v1.pdf) [code](https://github.com/microsoft/Cream/tree/main/iRPE)

* [arXiv 2021]  CrossFormer: A Versatile Vision Transformer Based on Cross-scale Attention [paper](https://arxiv.org/pdf/2108.00154v2.pdf) [code](https://github.com/cheerss/CrossFormer)

* [arXiv 2021] Training data-efficient image transformers & distillation through attention [paper](https://arxiv.org/pdf/2012.12877.pdf) [code](https://github.com/facebookresearch/deit)
